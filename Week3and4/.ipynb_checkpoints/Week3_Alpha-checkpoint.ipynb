{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f3e5ae71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from skimage.color import rgb2lab, lab2rgb, rgb2gray, xyz2lab\n",
    "from skimage.io import imsave\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import random\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "30f94264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get images\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Load the image using PIL\n",
    "image_path = 'woman.jpg'\n",
    "#image = Image.open(image_path)\n",
    "\n",
    "# Convert PIL Image to PyTorch tensor\n",
    "image_pil = Image.open(image_path).convert('RGB')\n",
    "\n",
    "image = np.array(image_pil)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "67895d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = rgb2lab(1.0/255*image)[:,:,0]\n",
    "Y = rgb2lab(1.0/255*image)[:,:,1:]\n",
    "Y /= 128\n",
    "X = X.reshape(1, 400, 400, 1)\n",
    "Y = Y.reshape(1, 400, 400, 2)\n",
    "X_original=X\n",
    "Y_original=Y\n",
    "#Conversion to Tensors\n",
    "#X = torch.from_numpy(X).float()\n",
    "#Y = torch.from_numpy(Y).float()\n",
    "\n",
    "X= torch.tensor(X, dtype=torch.float32).permute(0, 3, 1, 2) \n",
    "Y= torch.tensor(Y, dtype=torch.float32).permute(0, 3, 1, 2) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a60b1060",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CNNTranslationModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNTranslationModel, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 8, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv2 = nn.Conv2d(8, 8, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(8, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv4 = nn.Conv2d(16, 16, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv5 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv6 = nn.Conv2d(32, 32, kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        self.upsample1 = nn.Upsample(scale_factor=2)\n",
    "        self.conv7 = nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.upsample2 = nn.Upsample(scale_factor=2)\n",
    "        self.conv8 = nn.Conv2d(32, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.upsample3 = nn.Upsample(scale_factor=2)\n",
    "        self.conv9 = nn.Conv2d(16, 8, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv10 = nn.Conv2d(8, 2, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = F.relu(self.conv5(x))\n",
    "        x = F.relu(self.conv6(x))\n",
    "\n",
    "        x = self.upsample1(x)\n",
    "        x = F.relu(self.conv7(x))\n",
    "        x = self.upsample2(x)\n",
    "        x = F.relu(self.conv8(x))\n",
    "        x = self.upsample3(x)\n",
    "        x = F.relu(self.conv9(x))\n",
    "        x = F.tanh(self.conv10(x))\n",
    "\n",
    "        return x\n",
    "\n",
    "# Assuming the input shape is (batch_size, channels, height, width)\n",
    "model = CNNTranslationModel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ffe5316d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000, Loss: 0.0006113707786425948\n",
      "Epoch 101/1000, Loss: 0.0004401738988235593\n",
      "Epoch 201/1000, Loss: 0.00032931281020864844\n",
      "Epoch 301/1000, Loss: 0.0005954992957413197\n",
      "Epoch 401/1000, Loss: 0.00046015673433430493\n",
      "Epoch 501/1000, Loss: 0.0005111315986141562\n",
      "Epoch 601/1000, Loss: 0.00035566691076382995\n",
      "Epoch 701/1000, Loss: 0.00023971476184669882\n",
      "Epoch 801/1000, Loss: 0.0002944944426417351\n",
      "Epoch 901/1000, Loss: 0.000226885182200931\n"
     ]
    }
   ],
   "source": [
    "# Define optimizer and loss function\n",
    "optimizer = optim.RMSprop(model.parameters(), lr=0.001, alpha=0.9)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "\n",
    "# Training\n",
    "for epoch in range(1000):\n",
    "    # Forward pass\n",
    "    output = model(X)\n",
    "    \n",
    "    # Compute the loss\n",
    "    loss = criterion(output, Y)\n",
    "    \n",
    "    # Backward pass and optimization\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Print the loss every 100 epochs\n",
    "    if epoch % 100 == 0:\n",
    "        print(f'Epoch {epoch+1}/{1000}, Loss: {loss.item()}')\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "273f7b19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Loss: 0.00027899318956770003\n"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "with torch.no_grad():\n",
    "    # Convert the model to evaluation mode\n",
    "    model.eval()\n",
    "    # Prediction\n",
    "    output_tensor = model(X)\n",
    "    output_np = output_tensor.detach().numpy()\n",
    "\n",
    "    \n",
    "    # Evaluate the model on the entire dataset\n",
    "    eval_loss = criterion(model(X), Y)\n",
    "    print(f'Evaluation Loss: {eval_loss.item()}')\n",
    "\n",
    "\n",
    "# Post-process the output\n",
    "output_np *= 128\n",
    "cur = np.zeros((400, 400, 3))\n",
    "cur[:, :, 0] = X_original[0][:, :, 0]\n",
    "cur[:, :, 1:] = output_np[0].transpose(1,2,0)\n",
    "\n",
    "#cur = (cur * 255).astype(np.uint8)\n",
    "\n",
    "\n",
    "output_rgb = (lab2rgb(cur) * 255).astype(np.uint8)\n",
    "\n",
    "input_rgb = (rgb2gray(lab2rgb(cur)) * 255).astype(np.uint8)\n",
    "\n",
    "imsave(\"img_result.png\", output_rgb)\n",
    "imsave(\"img_gray_version.png\", input_rgb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47cb7a60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
